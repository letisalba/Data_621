---
title: "Data 621 - Blog 2"
author: "Leticia Salazar"
date: "November 8, 2022"
output: 
  html_document:
    theme: paper
    highlight: kate
    toc: True
    toc_float: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

$~$

## Simple Linear Regression

In simple linear regression, we look to find a relationship between two quantitative variables. We want to see how strong this relationship is and if the value of the dependent variable is at a certain value with the independent variable.

Below I'll demonstrate how to create a simple linear regression model using a common package in R called `diamonds` from the library `ggplot2`

$~$

### Load Libraries

Here we'll use `ggplot2` to be able to load the data set, but it is also a great visualization library. `Tidyverse` is also a great library for exploratory analysis of the data.

```{r, message=FALSE, warning=FALSE}
library(ggplot2)
library(tidyverse)
library(gtsummary) # great to summarize statistical tables
library(jtools) # use of summ() to view statistical info
```

-----------------

$~$

### Loading Data

Using the function `head()` will display the first few rows, therefore we can see the data set without it loading fully.
```{r, load data}
head(diamonds)
```

-----------------

### Data Exploration

Once loaded we can explore the data by using the `summary()`. This will summarize the variables including the following information for the numeric variables:

* minimum value
* first quartile (25th percentile)
* median value
* mean value
* third quartile (75th percentile)
* maximum value

For the rest of the variables we get the frequency count of the values.

```{r}
summary(diamonds)
```

$~$

Another exploratory function is `glimpse()` which provides a rundown of the columns along with how many rows and columns the data set has.
```{r}
glimpse(diamonds)
```

$~$

One of my recent favorites functions in R is `gtsummary` which was introduced to me by a peer. It offers a cleaner way to present these statistical information and there's various of customization options. For more information check references for the link on this function.

```{r}
sum1 <- diamonds %>% 
  select(c("carat", "depth", "table", "price"))
sum2 <- tbl_summary(sum1)
sum2
```

-----------------

### Data Preparation 

In most data sets, you have to prepare the data before you can start plotting or in this case building models. Since our data set doesn't need any cleaning or transformations we can go straight to model building. I have provided some tips below on how you can start prepping your data.

* Remove duplicate or irrelevant observations
* Fix structural errors
  * these include inconsistencies, typos, "n/a" and "not applicable" in a column, etc
* Filter unwanted outliers
  * careful, not all outliers are harmful when analyzing data
* Handle missing data
  * you can drop the observations with missing values but be mindful before removing it since you can lose information
  * you can input missing values but this may cause to lose integrity of the data
  * you can alter the data to use the null values effectively
* Validate
  * Ensure that the data makes sense in order to present accurate information 

-----------------

### Model Building

To fit a linear model in R we use the `lm()` function. Some parameters to consider for the function are:

`lm(fitting_formula, dataframe)`

* **fitting_formula**: determines the formula for the linear model
* **dataframe**: determines the name of the data frame 

Using the we get the statistical information on the selected model. It contains the following information: 

* **P-value**: it's associated with the model coefficients, any value less than 0.05 we can say that there's a statistically significant association between the variables.

* **Residual Standard Error**: it's the average distance that the observed values fall from the regression line. The lower the value the closer it is for the regression line to match with the observed data.

* **Multiple $R^2$**: it's the percentage of the variation in the variables being examined. The larger the $R^2$ value the better the explanatory variables are able to predict the value of the response variable.

* **Adjusted $R^2$**: the same as multiple $R^2$ but it takes into account the number of samples and variables you're using

* **F-Statistic**: global test to check if your model has at least one significant variable (non-zero). When combined with the p-value, you are able to tell the overall significance of the regression model.

* **T-value**: the predictor variable that's calculated as (Estimate) / (Standard Error)

* **Estimate**: shows us the average increase in the response variable associated with a one unit increase in the predictor variable, assuming all other predictor variables are constant.

```{r, first linear model}
# model 1 will consist of looking at the data overall
model <- lm(diamonds)
summ(model)
```

Using the `summ()` or `summary()` functions we get a clear view of the model fit values. Let's create a model to view the relationship between carat and price:

```{r second linear model}
# two variables used are carat over price
model_2 <- lm(carat ~ price, diamonds)
#summary(model_2)
summ(model_2)
```

The equation for a simple regression model is: $\hat{y}_i = \hat\beta_0 + \hat\beta_i x_i + \hat\epsilon_i$ where $\epsilon$ is the residual standard error ($\hat \sigma$).


-----------------

### Plotting

Not only does displaying the model's `summary()` function helpful to see if the model we have created describes a relationship between dependent and independent variables. Plotting the model is helpful in viewing these findings.

For a simple linear regression model we create a histogram as well as a Normal Q-Q Plot. The histogram will allow us to see if there's a normal distribution. 

Based on the plots below there's a right skeweness in the two variables we are using for `model_2`.

```{r}
# histogram
par(mfrow=c(1,2))
hist(diamonds$price, main = "Price Histogram", xlab = "price")
hist(diamonds$carat, main = "Carat Histogram", xlab = "carat")
```

$~$

The Q-Q plot will show the distribution of the data against the expected normal distribution. Our model's normal Q-Q plot shows that the qqline (in red), which passes through the first and third quartiles, passes through most of the residuals but there a few that don't.
```{r}
# define residuals
res <- resid(model_2)

#create Q-Q plot for residuals
qqnorm(res)

#add a straight diagonal line to the plot
qqline(res, col = "red")
```


Based on our model and plots we can assume that the model follows a nearly normal distribution and there's a strong relationship between the carat and price.

-----------------

$~$

## References:
* Zach. (2020, October 26). How to perform simple linear regression in R (step-by-step). Statology. Retrieved October 24, 2022, from https://www.statology.org/simple-linear-regression-in-r/ 
* Guide to data cleaning: Definition, benefits, components, and how to clean your data. Tableau. (n.d.). Retrieved October 24, 2022, from https://www.tableau.com/learn/articles/what-is-data-cleaning 
* How to use LM() function in R to fit linear models? GeeksforGeeks. (2021, December 19). Retrieved October 24, 2022, from https://www.geeksforgeeks.org/how-to-use-lm-function-in-r-to-fit-linear-models/#:~:text=The%20lm()%20function%20is,not%20in%20the%20data%20frame.
* Sjoberg DD, Whiting K, Curry M, Lavery JA, Larmarange J. Reproducible summary tables with the gtsummary package.
  The R Journal 2021;13:570â€“80. https://doi.org/10.32614/RJ-2021-053.
* Zach. (2020, October 26). How to perform simple linear regression in R (step-by-step). Statology. Retrieved November 1, 2022, from https://www.statology.org/simple-linear-regression-in-r/ 