---
title: "Data 621 - Homework 5"
author: "Group 2: William Aiken, Donald Butler, Michael Ippolito, Bharani Nittala,
  and Leticia Salazar"
date: "December 11, 2022"
output:
  pdf_document:
    dev: cairo_pdf
    toc: yes
  html_document:
    theme: yeti
    highlight: tango
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

$~$

## Overview:

We will explore, analyze and model a data set containing information on approximately 12,000 commercially available wines. The variables are mostly related to the chemical properties of the wine being sold. The response variable is the number of sample cases of wine that were purchased by wine distribution companies after sampling a wine. These cases would be used to provide tasting samples to restaurants and wine stores around the United States. The more sample cases purchased, the more likely is a wine to be sold at a high end restaurant. A larger wine manufacturer is studying the data in order to predict the number of wine cases ordered based upon the wine characteristics. If the wine manufacturer can predict the number of cases, then that manufacturer will be able to adjust their wine offering to maximize sales.

## Objective

Build a count regression model to predict the number of cases of wine that will be sold given certain properties of the wine. HINT: Sometimes, the face that a variable is missing is actually predictive of the target. 

## Description

Below is a short description of the variables of interest in the data set:


| VARIABLE NAME:      | DEFINITION:                                     | THEORETICAL EFFECT:               |
|:---                 |:---:                                            |:---:                              |
|INDEX                |Identification Variable (do not use)             |None                               |
|TARGET               |Number of Cases Purchased                        |None                               |
|AcidIndex            |Proprietary method of testing totalacidity of wine by using a weighted average |     |
|Alcohol              |Alcohol Content                                  |                                   |
|Chorides             |Cholride content of wine                         |                                   |
|CitricAcid           |Citric Acid Content                              |                                   |
|Density              |Density of Wine                                  |                                   |
|FixedAcidity         |Fixed Acidity of Wiine                           |                                   |
|FreeSulfurDioxide    |Sulfur Dioxide content of wine                   |                                   |
|LabelAppeal          |Marketing Score indicating the appeal of label design for consumers. High numbers suggest customers like the label design. Negative numbers suggest customers don't like the design.   | Many consumers purchase based on the visual appeal of the wine label design. Higher numbers suggest better sales.  |
|ResidualSugar        |Residual Sugar of wine                           |                                   |
|STARS                |Wine rating by a team of experts: 4 Stars = Excellent, 1 Star = Poor |A high number of stars suggests high sales   |
|Sulphates            |Sulfate content of Wine                          |                                   |
|TotalSulfurDioxide   |Total Sulfur Dioxide of Wine                     |                                   |
|VolatileAcidity      |Volatile Acid content of wine                    |                                   |
|pH                   |pH of wine                                       |                                   |

$~$

-----------

### Load Libraries:

These are the libraries used to explore, prepare, analyze and build our models
```{r libraries, warning=FALSE, message=FALSE}
library(tidyverse)
library(dplyr)
library(corrplot)
library(skimr)
library(DataExplorer)
library(ggplot2)
library(hrbrthemes)
library(mice)
library(MASS)
library(dvmisc)
library(gridExtra)
library(lattice)
```

$~$

## Load Data set:

We have included the original data sets in our GitHub account and read from this location. Below we are showing the training data set:
```{r, echo=FALSE}
dftrain <- read.csv("https://raw.githubusercontent.com/letisalba/Data_621/master/Homework_5/csv/wine-training-data.csv")
dfeval <- read.csv("https://raw.githubusercontent.com/letisalba/Data_621/master/Homework_5/csv/wine-evaluation-data.csv")
head(dftrain)
```

-----------

## Data Exploration:

Using the `summary()` function lets start exploring the training and evaluation data.

Training:
```{r, echo=FALSE}
summary(dftrain)
```
Evaluation:
```{r, echo=FALSE}
summary(dfeval)
```


Using the `DataExplorer` package we use the `create_report` function which pulls a full data profile from our training data set and create an html file with basic statistics, structure, missing data, distribution visualizations, correlation matrix and principal component analysis for our data. You can find these output in our github.

```{r, eval=FALSE, message=FALSE, warning=FALSE}
# Do not render since it will produce a separate html file
# Remove TARGET from eval report since it will contain all NAs and will make the correlation plot fail to render
DataExplorer::create_report(dftrain, output_file='training_report.html')
DataExplorer::create_report(dfeval %>% select(-TARGET), output_file='eval_report.html')
```

Based on this our training data includes 12795 records and 16 variables whereas the evaluation data includes 3335 records and 16 variables.

Training:
```{r, echo=FALSE}
str(dftrain)
```
Evaluation:
```{r, echo=FALSE}
str(dfeval)
```

Lets take a look at the distribution of each variables in the training data set.

Based on the plots below, we can tell that most of the variables seem to be normally distributed with the exception of `AcidIndex` and `STARS` being right skewed. `INDEX` shows a uniform distribution but has no effect on our data so during the data preparation stage we will be removing it. 

```{r distribution, echo=FALSE, warning=FALSE, fig.height = 10, fig.width = 10, fig.align="center"}
plot_train <- dftrain %>%
  gather(key = 'variable', value = 'value')

ggplot(plot_train) +
  geom_histogram(aes(x=value, y = ..density..), bins=30) +
  geom_density(aes(x=value), color='blue') +
  theme_ipsum() +
  facet_wrap(. ~variable, scales='free', ncol=4)
```

The fact that some wines are not rated could be a potential predictor. We'll treat NAs as its own star rating.
```{r, echo=FALSE}
# Create logical variable to indicate whether there is a star rating for this wine
dftrain <- dftrain %>%
    mutate(STARS=ifelse(is.na(STARS), 'NR', STARS))
dfeval <- dfeval %>%
    mutate(STARS=ifelse(is.na(STARS), 'NR', STARS))
```

We'll also look at the number of cases of wine sold against the predictors.

```{r warning=FALSE, fig.width=12, fig.heigh=16, echo=FALSE}
plt <- vector('list', ncol(dftrain) - 1)
for (i in seq(3, 16)) {  # skip INDEX and TARGET variables
    if (class(dftrain[, i]) == 'numeric') {
        tmpmin <- min(dftrain[, i], na.rm=T)
        tmpinterval <- (max(dftrain[, i], na.rm=T) - tmpmin) / 5
        tmpcuts <- c()
        for (j in seq(1, 5)) {
            tmpcuts <- c(tmpcuts, tmpmin + (j * tmpinterval))
        }
        #dftrain$x <- dftrain[, i] %>% cut(breaks=5, ordered_result=T, right=F)
        dftrain$x <- dftrain[, i] %>% cut(breaks=tmpcuts, ordered_result=T, right=F)
    } else {
        dftrain$x <- dftrain[, i]
    }
    dftmp <- dftrain %>% group_by(x) %>% summarize(ct=sum(TARGET))
    plt[[i]] <- barchart(dftmp$ct ~ dftmp$x, horiz=F, col='darkgreen', xlab=colnames(dftrain)[i], ylab='Cases')
}
dftrain <- subset(dftrain, select=-x)  # remove temporary variable
grid.arrange(grobs=plt[3:7], ncol=3, nrow=2)
grid.arrange(grobs=plt[8:13], ncol=3, nrow=2)
grid.arrange(grobs=plt[14:16], ncol=3, nrow=2)
```

As shown, more cases of wine are sold for mid-range values of all categories of acidity, sugar, chlorides, the dioxides, density, pH, sulphates, and alcohol. Surprisingly, more cases were sold for labels that had mid-range label appeal. A lower acid index seemed to indicate more cases sold. And more cases were sold for wines rated only two stars, indicating that consumers may consider higher-starred wines as too pricey.


$~$

## Data Preparation:

Data preparation was performed on both the training and evaluation data sets but will only be displayed for the training data. We'll also need to removing the `INDEX` variable.
```{r, echo=FALSE}
# For some reason R renamed the INDEX column to "Ã¯..INDEX"
dftrain <- dftrain %>% 
  dplyr::select(-INDEX)
```

```{r, echo=FALSE}
dfeval <- dfeval %>% 
  dplyr::select(-IN)
```

Now we'll impute missing values using R's Multiple Imputation by Chained Equations (MICE) package. We'll avoid imputing the STARS variable as the absence of a star rating may be a significant predictor.
```{r, echo=FALSE}
# Impute missing values in training data (except for STARS)
dftrain_imputed <- mice(dftrain %>% dplyr::select(-STARS), m=5, maxit=5, method='pmm')
cleandf <- complete(dftrain_imputed) %>%
    mutate(STARS = dftrain$STARS)

# Impute missing values in eval data (except for STARS and TARGET)
dfeval_imputed <- mice(dfeval %>% dplyr::select(-STARS, -TARGET), m=5, maxit=5, method='pmm')
cleandf_eval <- complete(dfeval_imputed) %>%
    mutate(STARS = dfeval$STARS, TARGET = dfeval$TARGET)
```

Lets look at another summary to make sure there aren't any NAs where we're not expecting them.

Training data:
```{r, echo=FALSE}
summary(cleandf)
```

$~$

Evaluation data:
```{r, echo=FALSE}
summary(cleandf_eval)
```


$~$

## Build Models:

Based on the data, we'll try two model types: a poisson general linear model and a Gaussian multiple linear model.

$~$

### Poisson Models:

* Possion Model 1
```{r, echo=FALSE}
p_mod1 <- glm(TARGET ~., family="poisson", data=cleandf)
summary(p_mod1)
```

* Possion Model with stepwise AIC approach
```{r, echo=FALSE}
p_mod2 <- stepAIC(p_mod1, trace = F)
summary(p_mod2)
```


### Multiple Linear Regression Models:

* MLR Model 1
```{r, echo=FALSE}
lm_mod1 <- lm(TARGET ~., data = cleandf)
aic_lm_mod1 = AIC(lm_mod1)
summary(lm_mod1)
```

* MLR Model 2
```{r, echo=FALSE}
lm_mod2 <- stepAIC(lm_mod1, trace = F)
aic_lm_mod2 = AIC(lm_mod2)
summary(lm_mod2)
```

$~$

## Select Models:

In this section, an optimal model will be selected based on its performance when trained on the data. To select the models, we'll use AIC and MSE to measure accuracy of the predicted values.

Below, the Poisson and Multiple Linear Regression models have been compared to select the model with the lowest AIC.

### Comparison of Poisson Models:

We'll need to compare the AIC's of each Poisson Model.

Poisson Model 1:
```{r, echo=FALSE}
aic_p_mod1 <- p_mod1$aic
aic_p_mod1
```

Poisson Model 2:
```{r, echo=FALSE}
aic_p_mod2 <- p_mod2$aic
aic_p_mod2
```

$~$

Poisson Model 2 proves to have the lower AIC of the two, with a 33947.74 AIC. Below is the formula for Poisson Model 2.
```{r, echo=FALSE}
# Poisson - Minimum AIC
c(p_mod1$formula,p_mod2$formula)[which.min(c(p_mod1$aic,p_mod2$aic))]
```

$~$

### Comparsion of Multiple Linar Models:

We'll need to compare the Adjusted R Squares of each Linear Model.

Linear Model 1:
```{r, echo=FALSE}
r2_lm_mod1 <- summary(lm_mod1)$adj.r.squared
r2_lm_mod1
```

Linear Model 2:
```{r, echo=FALSE}
r2_lm_mod2 <- summary(lm_mod2)$adj.r.squared
r2_lm_mod2
```

$~$

Linear Model 2 proves to have the higher Adjusted R Squares, with a value of 0.4544041. Below is the formula for Linear Model 2.
```{r, echo=FALSE}
# Multiple Linear Regression Model - Highest Adjusted R Squared
c(formula(lm_mod1),formula(lm_mod2))[which.max(c(summary(lm_mod1)$adj.r.squared, summary(lm_mod2)$adj.r.squared))]
```


### Mean Square Error:

The Mean Square Error measures the averaged square different between the estimated values and the actual value. The lower the value of the MSE, the more accurately the model is able to predict the values.

$$\large \text{MSE} = \large \frac{1}{n} \sum(y - \hat{y})^2$$

```{r, echo=FALSE}
mse <- function(df, model){
  mean((df$TARGET - predict(model))^2)
}
```


```{r, echo=FALSE, warning=FALSE}
mse_p_mod1 <- mse(cleandf, p_mod1)
mse_p_mod2 <- mse(cleandf, p_mod2)
mse_lm_mod1 <- get_mse(lm_mod1)
mse_lm_mod2 <- get_mse(lm_mod2)
```

$~$

### Comparison of Possion and Gaussian Linear Models:

By evaluating the AIC's and MSE's of each model, we can choose the best one be looking at the lowest AIC and lowest MSE.

```{r, echo=FALSE}
models <- c("Possion Model 1", "Possion Model 2", "Linear Model 1", "Linear Model 2")
#rows <- c("Models", "MSE", "AIC")
MSE <- list(mse_p_mod1, mse_p_mod2, mse_lm_mod1, mse_lm_mod2)
AIC <- list(aic_p_mod1, aic_p_mod2, aic_lm_mod1, aic_lm_mod2)
knitr::kable(rbind(MSE, AIC), col.names = models)
```

$~$

Based on the above, the linear model has better model statistics than the poisson model.

Prediction from optimal multiple linear regression model:
```{r, echo=FALSE}
prob2 <- predict(lm_mod2, cleandf_eval, interval ='prediction')
cleandf_eval$TARGET <- prob2[,1]
cleandf_eval %>% head(10) %>% as_tibble()
write.csv(cleandf_eval, "wine_predictions2.csv", row.names = FALSE)
```

$~$

## Appendix:

```{r, eval=FALSE}
# load libaries
library(tidyverse)
library(dplyr)
library(corrplot)
library(skimr)
library(DataExplorer)
library(ggplot2)
library(hrbrthemes)
library(mice)

# load data
dftrain <- read.csv("https://raw.githubusercontent.com/letisalba/Data_621/master/Homework_5/csv/wine-training-data.csv")
dfeval <- read.csv("https://raw.githubusercontent.com/letisalba/Data_621/master/Homework_5/csv/wine-evaluation-data.csv")
head(dftrain)

# summary of training and evaluation data sets
summary(dftrain)
summary(dfeval)

# Do not render since it will produce a separate html file
# Remove TARGET from eval report since it will contain all NAs and will make the correlation plot fail to render
DataExplorer::create_report(dftrain, output_file='training_report.html')
DataExplorer::create_report(dfeval %>% select(-TARGET), output_file='eval_report.html')

# structure of training and evaluation data 
str(dftrain)
str(dfeval)

# plotting distribution of training data 
plot_train <- dftrain %>%
  gather(key = 'variable', value = 'value')

ggplot(plot_train) +
  geom_histogram(aes(x=value, y = ..density..), bins=30) +
  geom_density(aes(x=value), color='blue') +
  theme_ipsum() +
  facet_wrap(. ~variable, scales='free', ncol=4)

# Create logical variable to indicate whether there is a star rating for this wine
dftrain <- dftrain %>%
    mutate(STARS=ifelse(is.na(STARS), 'NR', STARS))
dfeval <- dfeval %>%
    mutate(STARS=ifelse(is.na(STARS), 'NR', STARS))

#Look at the number of cases of wine sold against the predictors.
plt <- vector('list', ncol(dftrain) - 1)
for (i in seq(3, 16)) {  # skip INDEX and TARGET variables
    if (class(dftrain[, i]) == 'numeric') {
        tmpmin <- min(dftrain[, i], na.rm=T)
        tmpinterval <- (max(dftrain[, i], na.rm=T) - tmpmin) / 5
        tmpcuts <- c()
        for (j in seq(1, 5)) {
            tmpcuts <- c(tmpcuts, tmpmin + (j * tmpinterval))
        }
        #dftrain$x <- dftrain[, i] %>% cut(breaks=5, ordered_result=T, right=F)
        dftrain$x <- dftrain[, i] %>% cut(breaks=tmpcuts, ordered_result=T, right=F)
    } else {
        dftrain$x <- dftrain[, i]
    }
    dftmp <- dftrain %>% group_by(x) %>% summarize(ct=sum(TARGET))
    plt[[i]] <- barchart(dftmp$ct ~ dftmp$x, horiz=F, col='darkgreen', xlab=colnames(dftrain)[i], ylab='Cases')
}
dftrain <- subset(dftrain, select=-x)  # remove temporary variable
grid.arrange(grobs=plt[3:7], ncol=3, nrow=2)
grid.arrange(grobs=plt[8:13], ncol=3, nrow=2)
grid.arrange(grobs=plt[14:16], ncol=3, nrow=2)

# Removing INDEX from training and eval data 
# For some reason R renamed the INDEX column to "Ã¯..INDEX"
dftrain <- dftrain %>% 
  dplyr::select(-Ã¯..INDEX)
dfeval <- dfeval %>% 
  dplyr::select(-IN)

# Impute missing values in training data
dftrain_imputed <- mice(dftrain, m=5, maxit=5, method='pmm')
cleandf <- complete(dftrain_imputed) %>%
    mutate(STARS = dftrain$STARS)

# Impute missing values in eval data (except for TARGET)
dfeval_imputed <- mice(dfeval %>% select(-TARGET), m=5, maxit=5, method='pmm')
cleandf_eval <- complete(dfeval_imputed) %>%
    mutate(STARS = dfeval$STARS, TARGET = dfeval$TARGET)

# Look at another summary to make sure there aren't any NAs where we're not expecting them
summary(cleandf)
summary(cleandf_eval)

# Poisson model
p_mod1 <- glm(TARGET ~., family="poisson", data=cleandf)
summary(p_mod1)

# Possion Model with stepwise AIC approach
p_mod2 <- stepAIC(p_mod1, trace = F)
summary(p_mod2)

# Multiple Linear Regression Models:

# MLR Model 1
lm_mod1 <- lm(TARGET ~., data = cleandf)
aic_lm_mod1 = AIC(lm_mod1)
summary(lm_mod1)

# MLR Model 2
lm_mod2 <- stepAIC(lm_mod1, trace = F)
aic_lm_mod2 = AIC(lm_mod2)
summary(lm_mod2)

# Select Models:

# Comparison of Poisson Models:

# Poisson Model 1:
aic_p_mod1 <- p_mod1$aic
aic_p_mod1

# Poisson Model 2:
aic_p_mod2 <- p_mod2$aic
aic_p_mod2

# Poisson - Minimum AIC
c(p_mod1$formula,p_mod2$formula)[which.min(c(p_mod1$aic,p_mod2$aic))]

# Comparsion of Multiple Linar Models:

# Linear Model 1:
r2_lm_mod1 <- summary(lm_mod1)$adj.r.squared
r2_lm_mod1

# Linear Model 2:
r2_lm_mod2 <- summary(lm_mod2)$adj.r.squared
r2_lm_mod2

# Multiple Linear Regression Model - Highest Adjusted R Squared
c(formula(lm_mod1),formula(lm_mod2))[which.max(c(summary(lm_mod1)$adj.r.squared, summary(lm_mod2)$adj.r.squared))]

# Mean Square Error:
mse <- function(df, model){
  mean((df$TARGET - predict(model))^2)
}
mse_p_mod1 <- mse(cleandf, p_mod1)
mse_p_mod2 <- mse(cleandf, p_mod2)
mse_lm_mod1 <- get_mse(lm_mod1)
mse_lm_mod2 <- get_mse(lm_mod2)

# Comparison of Possion and Negative Binomial Model's:
models <- c("Possion Model 1", "Possion Model 2", "Linear Model 1", "Linear Model 2")
#rows <- c("Models", "MSE", "AIC")
MSE <- list(mse_p_mod1, mse_p_mod2, mse_lm_mod1, mse_lm_mod2)
AIC <- list(aic_p_mod1, aic_p_mod2, aic_lm_mod1, aic_lm_mod2)
knitr::kable(rbind(MSE, AIC), col.names = models)

# Prediction from optimal multiple linear regression model
prob2 <- predict(lm_mod2, cleandf_eval, interval ='prediction')
cleandf_eval$TARGET <- prob2[,1]
cleandf_eval %>% head(10) %>% as_tibble()
write.csv(cleandf_eval, "wine_predictions2.csv", row.names = FALSE)

```


-----------

## References:
https://englianhu.files.wordpress.com/2016/01/faraway-extending-the-linear-model-with-r-e28093-2006.pdf
