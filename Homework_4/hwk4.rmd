---
title: "Data 621 - Homework 4"
author: "Group 2: William Aiken, Donald Butler, Michael Ippolito, Bharani Nittala,
  and Leticia Salazar"
date: "November 6, 2022"
output:
  html_document:
    theme: yeti
    highlight: tango
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE, ref.label = knitr::all_labels(appendix == TRUE)}
knitr::opts_chunk$set(echo = TRUE, tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

## Overview:

In this homework assignment, you will explore, analyze and model a data set containing approximately 8,000 records representing a customer at an auto insurance company. Each record has two response variables. The first response variable, TARGET_FLAG, is a 1 or a 0. A “1” means that the person was in a car crash. A zero means that the person was not in a car crash. The second response variable is TARGET_AMT. This value is zero if the person did not crash their car. But if they did crash their car, this number will be a value greater than zero.

## Objective: 

Your objective is to build multiple linear regression and binary logistic regression models on the training data to predict the probability that a person will crash their car and also the amount of money it will cost if the person does crash their car. You can only use the variables given to you (or variables that you derive from the variables provided). Below is a short description of the variables of interest in the data set:

\newpage

## Description:

Below is a short description of the variables of interest in the data set:

| VARIABLE NAME:| DEFINITION:                             | THEORETICAL EFFECT:                                                                             |
|:---           |:---:                                    |:---:                                                                                            |
|INDEX          |Identification Variable (do not use)     |None                                                                                             |
|TARGET_FLAG    |Was Car in a crash? 1 = YES 2 = NO       |None                                                                                             |
|TARGET_AMT     |If car was in a crash, what was the cost |None                                                                                             |
|AGE            |Age of Driver                            |Very young people tend to be risky. Maybe very old people also.                                  |
|BLUEBOOK       |Value of Vehicle                         |Unknown effect on probability of collision, but probably effect the payout if there is a crash   |
|CAR_AGE        |Vehicle Age                              |Unknown effect on probability of collision, but probably effect the payout if there is a crash   |
|CAR_TYPE       |Type of Car                              |Unknown effect on probability of collision, but probably effect the payout if there is a crash   |
|CAR_USE        |Vehicle Use                              |Commercial vehicles are driven more, so might increase probability of collision                  |
|CLM_FREQ       |# Claims (Past 5 Years)                  |The more claims you filed in the past, the more you are likely to file in the future             |
|EDUCATION      |Max Education Level                      |Unknown effect, but in theory more educated people tend to drive more safely                     |
|HOMEKIDS       |# Children at Home                       |Unknown effect                                                                                   |
|HOME_VAL       |Home Value                               |In theory, home owners tend to drive more responsibly                                            |
|INCOME         |Income                                   |In theory, rich people tend to get into fewer crashes                                            |
|JOB            |Job Category                             |In theory, white collar jobs tend to be safer                                                    |
|KIDSDRIV       |# Driving Children                       |When teenagers drive your car, you are more likely to get into crashes                           |
|MSTATUS        |Martial Status                           |In theory, married people drive more safely                                                      |
|MVR_PTS        |Motor Vehicle Record Points              |If you get lots of traffic tickets, you tend to get into more crashes                            |
|OLDCLAIM       |Total Claims (Past 5 Years)              |If your total payout over the past five years was high, this suggests future payouts will be high|
|PARENT1        |Single Parent                            |Unknown effect                                                                                   |
|RED_CAR        |A Red Car                                |Urban legend says that red cars (especially red sports cars) are more risky. Is that true?       |
|REVOKED        |License Revoked (Past 7 Years)           |If your license was revoked in the past 7 years, you probably are a more risky driver.           |
|SEX            |Gender                                   |Urban legend says that women have less crashes then men. Is that true?                           |
|TIF            |Time in Force                            |People who have been customers for a long time are usually more safe.                            |
|TRAVTIME       |Distance to Work                         |Long drives to work usually suggest greater risk                                                 |
|URBANICITY     |Home / Work Area                         |Unknown                                                                                          |
|YOJ            |Years on Job                             |People who stay at a job for a long time are usually more safe                                   |

-----------

### Load Libraries:

These are the libraries used to explore, prepare, analyze and build our models
```{r libraries, warning=FALSE, message=FALSE}
library(tidyverse)
library(caret)
library(pROC)
library(corrplot)
library(GGally)
library(psych)
library(car)
library(kableExtra)
library(gridExtra)
library(performance)
library(faraway)
library(jtools)
library(DataExplorer)
library(hrbrthemes)
library(skimr)
library(MASS)
```

### Load Data set:

We have included the original data sets in our GitHub account and read from this location. Our training data set includes 8,161 records and 26 variables.
```{r, loading data, echo=FALSE}
dftrain <- read.csv("https://raw.githubusercontent.com/letisalba/Data_621/master/Homework_4/csv/insurance_training_data.csv")
dfeval <- read.csv("https://raw.githubusercontent.com/letisalba/Data_621/master/Homework_4/csv/insurance_training_data.csv")
glimpse(dftrain)
```

-----------


## Data Exploration:

For insight on the data we use the `summary()` function on the train dataset:
```{r, echo=FALSE}
summary(dftrain)
```


Let's look at the statistical summary for the `dfeval` data as well:
```{r, echo=FALSE}
summary(dfeval)
```

$~$

Distributions for training data set

```{r fig.height = 10, fig.width = 10, echo=FALSE, fig.align='center'}
DataExplorer::plot_bar(
  data = dftrain,
         order_bar = T,
         ggtheme=theme_ipsum())
```

```{r, fig.height = 10, fig.width = 10, echo=FALSE, fig.align='center'}
DataExplorer::plot_histogram(
  geom_histogram_args = list(alpha = 0.5),
   data = dftrain,
         ggtheme=theme_ipsum())
```

$~$

The following dummy variables are done to both the training and evaluation data set and only showing the results for the training data.

#### PARENT1

The *PARENT1* variable has two values, Yes and No, to indicate if the observation is a single parent. We will construct a dummy variable *SingleParent* = 1 if *PARENT1* = Yes.

```{r, echo=FALSE}
dftrain %>% count(PARENT1)
```


$~$

#### SEX

The *SEX* variable has two values, M and z_F. We will create a dummy variable *Male* = 1 if *SEX* = M.

```{r, echo=FALSE}
dftrain %>% count(SEX)
```


$~$

#### MSTATUS

The variable *MSTATUS* has two values, Yes and z_No, to indicate the marital status. We will create a dummy variable *Married* = 1 if MSTATUS = Yes.

```{r, echo=FALSE}
dftrain %>% count(MSTATUS)
```


$~$

#### EDUCATION

The *EDUCATION* variable takes on 5 values ranging from less than high school through PHD. We will construct dummy variables: *HighSchool*, *Bachelors*, *Masters*, *PHD*, to indicate the highest level of education completed.

```{r, echo=FALSE}
dftrain %>% count(EDUCATION)
```


$~$

#### JOB

The *JOB* variable takes on 8 values. The *JOB* variable has 526 missing values, so we will construct dummy variables for all 8 values assuming the missing values are not one of the listed professions. The dummy variables we will create are: *Clerical*, *Doctor*, *HomeMaker*, *Lawyer*, *Manager*, *Professional*, *Student*, and *BlueCollar*.

```{r, echo=FALSE}
dftrain %>% count(JOB)
```

$~$

#### CAR_USE

The *CAR_USE* variable has two values, Commercial and Private. We will construct a dummy variable *Commercial* = 1 if Commercial.

```{r, echo=FALSE}
dftrain %>% count(CAR_USE)
```

$~$

#### CAR_TYPE

The *CAR_TYPE* variable takes on 6 values. We will create dummy variables; *Minivan*, *PanelTruck*, *Pickup*, *SportsCar*, and *Van*.

```{r, echo=FALSE}
dftrain %>% count(CAR_TYPE)
```


$~$

#### RED_CAR

The *RED_CAR* variable has two values, yes and no. We will create a dummy variable *RedCar* = 1 if *RED_CAR* = yes.

```{r, echo=FALSE}
dftrain %>% count(RED_CAR)
```

$~$

#### REVOKED

The *REVOKED* variable has two values, Yes and No. We will create a dummy variable *DLRevoked* = 1 if *REVOKED* = Yes.

```{r, echo=FALSE}
dftrain %>% count(REVOKED)
```

$~$

#### URBANICITY

The *URBANICITY* variable has two values, Highly Urban/ Urban and z_Highly Rural/ Rural. We will create a dummy variable *Urban* = 1 if *URBANICITY* = Highly Urban/ Urban.

```{r, echo=FALSE}
dftrain %>% count(URBANICITY)
```

-----------

## Data Preparation:

Performed to both the training and evaluation data sets.

$~$

#### Data Cleaning Function

* The attributes `BLUEBOOK`, `HOME_VAL`, `INCOME`, and` OLDCLAIM` are dollar amounts stored as characters. Need to convert to int.
* Variables with NA: `AGE` (6), `YOJ` (454), `CAR_AGE` (510)
* Consider creating `AGE` groups Under25 and Over65 to account for young and older drivers.
* Consider creating `CAR_AGE` groups to identify new cars. One observation has a `CAR_AGE` = -3, which shouldn't be possible.
* Consider creating `YOJ` (Year on Job) groups to identify job stability; Over5years etc.


```{r, echo=FALSE}
clean_df <- function(df) {

  df$BLUEBOOK <- as.numeric(gsub('[$,]','',df$BLUEBOOK))
  df$HOME_VAL <- as.numeric(gsub('[$,]','',df$HOME_VAL))
  df$INCOME <- as.numeric(gsub('[$,]','',df$INCOME))
  df$OLDCLAIM <- as.numeric(gsub('[$,]','',df$OLDCLAIM))

  df <- df %>%
    mutate(SingleParent = ifelse(PARENT1 == 'Yes', 1, 0)) %>% dplyr::select(-PARENT1) %>%
    mutate(Male = ifelse(SEX == 'M', 1, 0)) %>% dplyr::select(-SEX) %>%
    mutate(Married = ifelse(MSTATUS == 'Yes', 1, 0)) %>% dplyr::select(-MSTATUS) %>%
    mutate(HighSchool = ifelse(EDUCATION == 'z_High School', 1, 0)) %>%
    mutate(Bachelors = ifelse(EDUCATION == 'Bachelors', 1, 0)) %>%
    mutate(Masters = ifelse(EDUCATION == 'Masters', 1, 0)) %>%
    mutate(PHD = ifelse(EDUCATION == 'PhD', 1, 0)) %>% dplyr::select(-EDUCATION) %>%
    mutate(Clerical = ifelse(JOB == 'Clerical', 1, 0)) %>%
    mutate(Doctor = ifelse(JOB == 'Doctor', 1, 0)) %>%
    mutate(HomeMaker = ifelse(JOB == 'Home Maker', 1, 0)) %>%
    mutate(Lawyer = ifelse(JOB == 'Lawyer', 1, 0)) %>%
    mutate(Manager = ifelse(JOB == 'Manager', 1, 0)) %>%
    mutate(Professional = ifelse(JOB == 'Professional', 1, 0)) %>%
    mutate(Student = ifelse(JOB == 'Student', 1, 0)) %>%
    mutate(BlueCollar = ifelse(JOB == 'z_Blue Collar', 1, 0)) %>% dplyr::select(-JOB) %>%
    mutate(Commercial = ifelse(CAR_USE == 'Commercial', 1, 0)) %>% dplyr::select(-CAR_USE) %>%
    mutate(Minivan = ifelse(CAR_TYPE == 'Minivan', 1, 0)) %>%
    mutate(PanelTruck = ifelse(CAR_TYPE == 'Panel Truck', 1, 0)) %>%
    mutate(Pickup = ifelse(CAR_TYPE == 'Pickup', 1, 0)) %>%
    mutate(SportsCar = ifelse(CAR_TYPE == 'Sports Car', 1, 0)) %>%
    mutate(Van = ifelse(CAR_TYPE == 'Van', 1, 0)) %>% dplyr::select(-CAR_TYPE) %>%
    mutate(RedCar = ifelse(RED_CAR == 'yes', 1, 0)) %>% dplyr::select(-RED_CAR) %>%
    mutate(DLRevoked = ifelse(REVOKED == 'Yes', 1, 0)) %>% dplyr::select(-REVOKED) %>%
    mutate(Urban = ifelse(URBANICITY == 'Highly Urban/ Urban', 1, 0)) %>% dplyr::select(-URBANICITY)
  return(df)
}

cleandf <- clean_df(dftrain)
head(cleandf)
```


$~$

The correlation plot below is measuring the degree of linear relationship within the cleaned training data. The values in which this is measured falls between -1 and +1, with +1 being a strong positive correlation and -1 a strong negative correlation.


```{r corr-plot, fig.height = 10, fig.width = 10, echo=FALSE, fig.align='center'}
cor_res <- cor(cleandf, use = "na.or.complete")

corrplot(cor_res,
         type = "lower",
         order = "original",
         tl.col = "black",
         tl.srt = 50,
         tl.cex = 1)
cor_res <- data.frame(cor_res)
```
$~$

-----------

## Model Building:

We will be building six different models; three multiple linear regression models and three binary logistic regression models.

**Model 1**

Base model 
```{r, echo=FALSE}
model1 <- lm(TARGET_AMT ~., cleandf, na.action = na.omit)
summary(model1)
#summ(model1)
```

$~$

**Model 2**

```{r, echo=FALSE}
model2 <- lm(TARGET_AMT ~ KIDSDRIV + HOMEKIDS + INCOME + SingleParent + HOME_VAL + Married + TRAVTIME + BLUEBOOK + TIF + CLM_FREQ + MVR_PTS + CAR_AGE, cleandf, na.action = na.omit)
summary(model2)
#summ(model2)
```

$~$

**Model 3**

BoxCox transformation
```{r, echo=FALSE}
model_boxcox <- preProcess(cleandf, c("BoxCox"))
model_bc_transformed <- predict(model_boxcox, cleandf)
model4 <- lm(TARGET_AMT ~ ., model_bc_transformed)
summary(model4)
```

$~$

**Model 4**
Full Binary logistic regression model
```{r, echo=FALSE}
model4 <- glm(TARGET_FLAG ~., cleandf, family = binomial(link = "logit"))
summary(model4)
```

$~$

**Model 5**

The `dropterm()` function from the MASS package tests all models from the current model selected by fitting all models that differ from the current model by dropping a single term, maintaining marginality.

```{r, echo=FALSE, warning=FALSE}
dropterm(model4, test = "F")
```


Working on model 5
```{r, echo=FALSE}
model5 <- glm(TARGET_FLAG ~ INDEX + TARGET_AMT + KIDSDRIV + AGE + HOMEKIDS + 
    YOJ + INCOME + HOME_VAL + TRAVTIME + BLUEBOOK + TIF + OLDCLAIM + 
    CLM_FREQ + MVR_PTS + CAR_AGE + SingleParent + Male + Married + 
    HighSchool + Bachelors + Masters + PHD + Clerical + Doctor + 
    HomeMaker + Lawyer + Manager + Professional + Student + BlueCollar + 
    Commercial + Minivan + PanelTruck + Pickup + SportsCar + 
    Van + RedCar + DLRevoked + Urban, cleandf, family = binomial(link = "logit"))
summary(model5)
```

$~$

**Model 6**
Backward Elimination
```{r, echo=FALSE, warning=FALSE}
model6 <- glm(TARGET_FLAG ~ INDEX + TARGET_AMT + KIDSDRIV + AGE + HOMEKIDS + 
    YOJ + HOME_VAL + TRAVTIME + BLUEBOOK + TIF + OLDCLAIM + 
    CLM_FREQ + CAR_AGE + SingleParent + Male + Married + Bachelors + Clerical + Doctor + 
    HomeMaker + Lawyer + Manager + Student + BlueCollar + 
    Commercial + Minivan + PanelTruck + Pickup + SportsCar + 
    Van + RedCar + Urban, data = cleandf, family=binomial(link="logit"))
summary(model6)
```



```{r}

```


$~$
-----------

## Select Models: 

-----------

$~$

## Appendix:

Below is all the code used in this homework
```{r, eval=TRUE}
# load libraries
library(tidyverse)
library(caret)
library(pROC)
library(corrplot)
library(GGally)
library(psych)
library(car)
library(kableExtra)
library(gridExtra)
library(performance)
library(faraway)
library(jtools)

# load data
dftrain <- read.csv("https://raw.githubusercontent.com/letisalba/Data_621/master/Homework_4/csv/insurance_training_data.csv")
dfeval <- read.csv("https://raw.githubusercontent.com/letisalba/Data_621/master/Homework_4/csv/insurance_training_data.csv")
glimpse(dftrain)

# summary of training data
summary(dftrain)

# creating dummy variables for some variables in training and evaluation data sets
dftrain %>% count(PARENT1)
dfeval %>% count(PARENT1)

dftrain %>% count(SEX)
dfeval %>% count(SEX)

dftrain %>% count(MSTATUS)
dfeval %>% count(MSTATUS)

dftrain %>% count(EDUCATION)
dfeval %>% count(EDUCATION)

dftrain %>% count(JOB)
dfeval %>% count(JOB)

dftrain %>% count(CAR_USE)
dfeval %>% count(CAR_USE)

dftrain %>% count(CAR_TYPE)
dfeval %>% count(CAR_TYPE)

dftrain %>% count(RED_CAR)
dfeval %>% count(RED_CAR)

dftrain %>% count(REVOKED)
dfeval %>% count(REVOKED)

dftrain %>% count(URBANICITY)
dfeval %>% count(URBANICITY)

# data cleaning functions for training data
clean_df <- function(df) {

  df$BLUEBOOK <- as.numeric(gsub('[$,]','',df$BLUEBOOK))
  df$HOME_VAL <- as.numeric(gsub('[$,]','',df$HOME_VAL))
  df$INCOME <- as.numeric(gsub('[$,]','',df$INCOME))
  df$OLDCLAIM <- as.numeric(gsub('[$,]','',df$OLDCLAIM))

  df <- df %>%
    mutate(SingleParent = ifelse(PARENT1 == 'Yes', 1, 0)) %>% select(-PARENT1) %>%
    mutate(Male = ifelse(SEX == 'M', 1, 0)) %>% select(-SEX) %>%
    mutate(Married = ifelse(MSTATUS == 'Yes', 1, 0)) %>% select(-MSTATUS) %>%
    mutate(HighSchool = ifelse(EDUCATION == 'z_High School', 1, 0)) %>%
    mutate(Bachelors = ifelse(EDUCATION == 'Bachelors', 1, 0)) %>%
    mutate(Masters = ifelse(EDUCATION == 'Masters', 1, 0)) %>%
    mutate(PHD = ifelse(EDUCATION == 'PhD', 1, 0)) %>% select(-EDUCATION) %>%
    mutate(Clerical = ifelse(JOB == 'Clerical', 1, 0)) %>%
    mutate(Doctor = ifelse(JOB == 'Doctor', 1, 0)) %>%
    mutate(HomeMaker = ifelse(JOB == 'Home Maker', 1, 0)) %>%
    mutate(Lawyer = ifelse(JOB == 'Lawyer', 1, 0)) %>%
    mutate(Manager = ifelse(JOB == 'Manager', 1, 0)) %>%
    mutate(Professional = ifelse(JOB == 'Professional', 1, 0)) %>%
    mutate(Student = ifelse(JOB == 'Student', 1, 0)) %>%
    mutate(BlueCollar = ifelse(JOB == 'z_Blue Collar', 1, 0)) %>% select(-JOB) %>%
    mutate(Commercial = ifelse(CAR_USE == 'Commercial', 1, 0)) %>% select(-CAR_USE) %>%
    mutate(Minivan = ifelse(CAR_TYPE == 'Minivan', 1, 0)) %>%
    mutate(PanelTruck = ifelse(CAR_TYPE == 'Panel Truck', 1, 0)) %>%
    mutate(Pickup = ifelse(CAR_TYPE == 'Pickup', 1, 0)) %>%
    mutate(SportsCar = ifelse(CAR_TYPE == 'Sports Car', 1, 0)) %>%
    mutate(Van = ifelse(CAR_TYPE == 'Van', 1, 0)) %>% select(-CAR_TYPE) %>%
    mutate(RedCar = ifelse(RED_CAR == 'yes', 1, 0)) %>% select(-RED_CAR) %>%
    mutate(DLRevoked = ifelse(REVOKED == 'Yes', 1, 0)) %>% select(-REVOKED) %>%
    mutate(Urban = ifelse(URBANICITY == 'Highly Urban/ Urban', 1, 0)) %>% select(-URBANICITY)
  return(df)
}

cleandf <- clean_df(dftrain)
head(cleandf)

# data cleaning functions for evaluation data
eval_clean_df <- function(df) {

  df$BLUEBOOK <- as.numeric(gsub('[$,]','',df$BLUEBOOK))
  df$HOME_VAL <- as.numeric(gsub('[$,]','',df$HOME_VAL))
  df$INCOME <- as.numeric(gsub('[$,]','',df$INCOME))
  df$OLDCLAIM <- as.numeric(gsub('[$,]','',df$OLDCLAIM))

  df <- df %>%
    mutate(SingleParent = ifelse(PARENT1 == 'Yes', 1, 0)) %>% select(-PARENT1) %>%
    mutate(Male = ifelse(SEX == 'M', 1, 0)) %>% select(-SEX) %>%
    mutate(Married = ifelse(MSTATUS == 'Yes', 1, 0)) %>% select(-MSTATUS) %>%
    mutate(HighSchool = ifelse(EDUCATION == 'z_High School', 1, 0)) %>%
    mutate(Bachelors = ifelse(EDUCATION == 'Bachelors', 1, 0)) %>%
    mutate(Masters = ifelse(EDUCATION == 'Masters', 1, 0)) %>%
    mutate(PHD = ifelse(EDUCATION == 'PhD', 1, 0)) %>% select(-EDUCATION) %>%
    mutate(Clerical = ifelse(JOB == 'Clerical', 1, 0)) %>%
    mutate(Doctor = ifelse(JOB == 'Doctor', 1, 0)) %>%
    mutate(HomeMaker = ifelse(JOB == 'Home Maker', 1, 0)) %>%
    mutate(Lawyer = ifelse(JOB == 'Lawyer', 1, 0)) %>%
    mutate(Manager = ifelse(JOB == 'Manager', 1, 0)) %>%
    mutate(Professional = ifelse(JOB == 'Professional', 1, 0)) %>%
    mutate(Student = ifelse(JOB == 'Student', 1, 0)) %>%
    mutate(BlueCollar = ifelse(JOB == 'z_Blue Collar', 1, 0)) %>% select(-JOB) %>%
    mutate(Commercial = ifelse(CAR_USE == 'Commercial', 1, 0)) %>% select(-CAR_USE) %>%
    mutate(Minivan = ifelse(CAR_TYPE == 'Minivan', 1, 0)) %>%
    mutate(PanelTruck = ifelse(CAR_TYPE == 'Panel Truck', 1, 0)) %>%
    mutate(Pickup = ifelse(CAR_TYPE == 'Pickup', 1, 0)) %>%
    mutate(SportsCar = ifelse(CAR_TYPE == 'Sports Car', 1, 0)) %>%
    mutate(Van = ifelse(CAR_TYPE == 'Van', 1, 0)) %>% select(-CAR_TYPE) %>%
    mutate(RedCar = ifelse(RED_CAR == 'yes', 1, 0)) %>% select(-RED_CAR) %>%
    mutate(DLRevoked = ifelse(REVOKED == 'Yes', 1, 0)) %>% select(-REVOKED) %>%
    mutate(Urban = ifelse(URBANICITY == 'Highly Urban/ Urban', 1, 0)) %>% select(-URBANICITY)
  return(df)
}

eval_cleandf <- eval_clean_df(dfeval)
head(eval_cleandf)

# model building for multiple linear regression
model1 <- lm(TARGET_AMT ~., cleandf, na.action = na.omit)
summary(model1)

# model building for binary logistic regression


# model selection

```


