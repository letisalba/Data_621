mutate(TP = ifelse(class == 1 & scored.class == 1,1,0),
FN = ifelse(class == 1 & scored.class == 0,1,0))
TP = sum(df$TP)
FN = sum(df$FN)
return(TP/(TP+FN))
}
paste0('The sensitivity of the predictions is ', round(func.sensitivity(class_df),5))
func.specificity <- function(data) {
df <- data %>%
mutate(TN = ifelse(class == 0 & scored.class == 0,1,0),
FP = ifelse(class == 0 & scored.class == 1,1,0))
TN = sum(df$TN)
FP = sum(df$FP)
return(TN/(TN+FP))
}
paste0('The specificity of the predictions is ', round(func.specificity(class_df),5))
# Calculate precision using dynamic column names
calcPrecision <- function(df, actualCol, predictedCol) {
TP <- nrow(df %>% filter((!!sym(actualCol)) == 1 & (!!sym(predictedCol)) == 1))
FP <- nrow(df %>% filter((!!sym(actualCol)) == 0 & (!!sym(predictedCol)) == 1))
return(TP / (TP + FP))
}
calcPrecision(df, 'class', 'scored.class')
# Calculate precision using dynamic column names
calcPrecision <- function(df, actualCol, predictedCol) {
TP <- nrow(df %>% filter((!!sym(actualCol)) == 1 & (!!sym(predictedCol)) == 1))
FP <- nrow(df %>% filter((!!sym(actualCol)) == 0 & (!!sym(predictedCol)) == 1))
return(TP / (TP + FP))
}
calcPrecision(df, 'class', 'scored.class')
knitr::opts_chunk$set(echo = TRUE, tidy.opts=list(width.cutoff=60),tidy=TRUE)
library(pROC)
library(caret)
library(tidyverse)
# load data set
class_df <- read.csv("https://raw.githubusercontent.com/letisalba/Data_621/master/Homework_2/csv/classification-output-data.csv")
head(class_df, n = 4)
summary(class_df)
str(class_df)
class_df %>%
select(class, scored.class) %>%
# re-coding to label the 0's and 1's
mutate(class = recode(class,
'0' = 'Actual Negative',
'1' = 'Actual Positive'),
scored.class = recode(scored.class,
'0' = 'Predicted Negative',
'1' = 'Predicted Positive')) %>%
table()
func.accuracy <- function (class_df, actual, predict) {
accuracy <- sum(class_df[actual] == class_df[predict]) / nrow(class_df)
return (accuracy)
}
paste0('The accuracy of the predictions is ', round(func.accuracy(class_df,"class","scored.class"),5))
func.error_rate <- function(data) {
df <- data %>%
mutate(TP = ifelse(class == 1 & scored.class == 1,1,0),
TN = ifelse(class == 0 & scored.class == 0,1,0),
FP = ifelse(class == 0 & scored.class == 1,1,0),
FN = ifelse(class == 1 & scored.class == 0,1,0))
TP = sum(df$TP)
TN = sum(df$TN)
FP = sum(df$FP)
FN = sum(df$FN)
return((FP+FN)/(TP+FP+TN+FN))
}
error_rate <- func.error_rate(class_df)
#accuracy <- func.accuracy(class_df)
accuracy <- func.accuracy(class_df,"class","scored.class")
# Verify that you get an accuracy and an error rate that sums to one.
paste0('The accuracy and error rate sums to ', (accuracy + error_rate))
func.precision <- function(data) {
df <- data %>%
mutate(TP = ifelse(class == 1 & scored.class == 1,1,0),
FP = ifelse(class == 0 & scored.class == 1,1,0))
TP = sum(df$TP)
FP = sum(df$FP)
return(TP/(TP+FP))
}
paste0('The precision of the predictions is ',round(func.precision(class_df),5))
func.sensitivity <- function(data) {
df <- data %>%
mutate(TP = ifelse(class == 1 & scored.class == 1,1,0),
FN = ifelse(class == 1 & scored.class == 0,1,0))
TP = sum(df$TP)
FN = sum(df$FN)
return(TP/(TP+FN))
}
paste0('The sensitivity of the predictions is ', round(func.sensitivity(class_df),5))
func.specificity <- function(data) {
df <- data %>%
mutate(TN = ifelse(class == 0 & scored.class == 0,1,0),
FP = ifelse(class == 0 & scored.class == 1,1,0))
TN = sum(df$TN)
FP = sum(df$FP)
return(TN/(TN+FP))
}
paste0('The specificity of the predictions is ', round(func.specificity(class_df),5))
# Calculate precision using dynamic column names
calcPrecision <- function(df, actualCol, predictedCol) {
TP <- nrow(df %>% filter((!!sym(actualCol)) == 1 & (!!sym(predictedCol)) == 1))
FP <- nrow(df %>% filter((!!sym(actualCol)) == 0 & (!!sym(predictedCol)) == 1))
return(TP / (TP + FP))
}
calcPrecision(df, 'class', 'scored.class')
shiny::runApp('~/Desktop/DATA_608/module3/Data-608-Hwk3')
runApp('~/Desktop/DATA_608/module3/Data-608-Hwk3')
str(data)
library(shiny)
library(tidyverse)
library(ggplot2)
library(rsconnect)
library(plotly)
data <- read.csv("https://raw.githubusercontent.com/charleyferrari/CUNY_DATA_608/master/module3/data/cleaned-cdc-mortality-1999-2010-2.csv", header = TRUE)
str(data)
runApp('~/Desktop/DATA_608/module3/Data-608-Hwk3')
# Define UI for app that draws a histogram ----
ui <- fluidPage(
# App title ----
titlePanel("Crude Mortality Rate"),
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
# Input: Slider for the number of bins ----
selectInput(inputId = y,'Selected ICD.Chapter:',
choices = infec_diseases$ICD.Chapter,
selected = 'State')
),
# Main panel for displaying outputs ----
mainPanel(
# Output: Histogram ----
plotlyOutput('distPlot', height = "700px", width = "600px")
)
)
)
# Define UI for app that draws a histogram ----
ui <- fluidPage(
# App title ----
titlePanel("Crude Mortality Rate"),
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
# Input: Slider for the number of bins ----
selectInput(inputId = 'y','Selected ICD.Chapter:',
choices = infec_diseases$ICD.Chapter,
selected = 'State')
),
# Main panel for displaying outputs ----
mainPanel(
# Output: Histogram ----
plotlyOutput('distPlot', height = "700px", width = "600px")
)
)
)
library(shiny)
library(tidyverse)
library(ggplot2)
library(rsconnect)
library(plotly)
data <- read.csv("https://raw.githubusercontent.com/charleyferrari/CUNY_DATA_608/master/module3/data/cleaned-cdc-mortality-1999-2010-2.csv", header = TRUE)
str(data)
summary(data)
colnames(data)
colSums(is.na(data))
rsconnect::setAccountInfo(name='letisalba', token='18C2DF783293E23721636AD4A43F97C6', secret='seSfGaZ7eiF653BaFtyAGHFls/Z66OE/t7Sk2b9A')
infec_diseases <- filter(data, Year == '2010' & ICD.Chapter == 'Certain infectious and parasitic diseases')
infec_diseases <- infec_diseases %>%
arrange(Crude.Rate)
head(infec_diseases)
# plot
infec_diseases %>%
ggplot(aes(x = reorder(State, -Crude.Rate), y = Crude.Rate)) +
geom_bar(stat = "identity") +
theme(axis.text = element_text(size = 6), panel.background = element_rect(fill = "white")) +
geom_col(fill = "blue")+
coord_flip() +
xlab("State") +
ylab("Crude Rate") +
geom_text(aes(label = Crude.Rate), vjust = 0.6, hjust = -0.4, size = 2, color="black")
fig <- infec_diseases %>% plot_ly()
fig <- fig %>% add_trace(x = ~Crude.Rate, y = ~State, type = 'bar',
text = y, textposition = 'auto',
marker = list(color = 'rgb(158,202,225)',
line = list(color = 'rgb(8,48,107)', width = 1.5)))
# Define UI for app that draws a histogram ----
ui <- fluidPage(
# App title ----
titlePanel("Crude Mortality Rate"),
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
# Input: Slider for the number of bins ----
selectInput(inputId = 'y','Selected ICD.Chapter:',
choices = infec_diseases$ICD.Chapter,
selected = 'State')
),
# Main panel for displaying outputs ----
mainPanel(
# Output: Histogram ----
plotlyOutput('distPlot', height = "700px", width = "600px")
)
)
)
# Define server logic required to draw a bargraph
server <- function(input, output) {
output$distPlot <- renderPlotly({fig})
}
# Run the application
shinyApp(ui, server)
# Define UI for app that draws a histogram ----
ui <- fluidPage(
# App title ----
titlePanel("Crude Mortality Rate"),
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
# Input: Slider for the number of bins ----
selectInput(inputId = 'y','Selected ICD.Chapter:',
choices = infec_diseases$ICD.Chapter,
selected = 'State')
),
# Main panel for displaying outputs ----
mainPanel(
# Output: Histogram ----
plotlyOutput('distPlot', height = "700px", width = "600px")
)
)
)
# Define server logic required to draw a bargraph
server <- function(input, output) {
output$distPlot <- renderPlotly({fig})
}
# Run the application
shinyApp(ui, server)
infec_diseases_2 <- data %>%
group_by(Year == "2010", ICD.Chapter == "Certain infectious and parasitic diseases") %>%
mutate(Crude.Rate.2 = round(
sum(Deaths) / sum(Population) * 100000),3) %>%
group_by(Year, ICD.Chapter, State)
head(infec_diseases_2)
state = "CA"
fig_2<- infec_diseases_2 %>%
plot_ly(x = ~Year, y = ~Crude.Rate, type ='bar',
text = y, textposition = 'auto',
marker = list(color = 'rgb(158,202,225)'),
name = 'State') %>% # Chart State and US Crude Rates next to one another
add_trace(x = ~Year, y = ~Crude.Rate.2, type='bar',
text = y, textposition = 'auto',
marker = list(color = 'rgb(58,200,225)'), name = 'US')  %>%
layout(title = "Crude death rate by state [CA]",
barmode = 'group',
xaxis = list(title = "Year"),
yaxis = list(title = "Crude death rate"))
# Define UI for app that draws a histogram ----
ui <- fluidPage(
# App title ----
titlePanel("Crude Mortality Rate"),
# Sidebar layout with input and output definitions ----
sidebarLayout(
# Sidebar panel for inputs ----
sidebarPanel(
# Input: Slider for the number of bins ----
selectInput(inputId = 'y','Selected ICD.Chapter:',
choices = infec_diseases_2$ICD.Chapter,
selected = 'State')
),
# Main panel for displaying outputs ----
mainPanel(
# Output: Create barchart
plotlyOutput('distPlot2')
)
)
)
server <- function(input, output) {
output$distPlot2 <- renderPlotly({fig_2})
}
shinyApp(ui, server)
rsconnect::deployApp('/Users/letiix3/Desktop/DATA_608/module3')
knitr::opts_chunk$set(echo = TRUE, tidy.opts=list(width.cutoff=60),tidy=TRUE)
library(pROC)
library(caret)
library(tidyverse)
library(dplyr)
devtools::install_url("http://cran.r-project.org/src/contrib/Archive/dplyr/dbplyr1.3.0.tar.gz")
devtools::install_url("http://cran.r-project.org/src/contrib/Archive/dplyr/dbplyr1.3.0.tar.gz")
devtools::install_url(https://cran.r-project.org/src/contrib/Archive/dbplyr/dbplyr_1.3.0.tar.gz )
devtools::install_url(http://cran.r-project.org/src/contrib/Archive/dbplyr/dbplyr_1.3.0.tar.gz)
BiocManager::install("AnnotationHub", version = "3.10", dependencies = TRUE)
knitr::opts_chunk$set(echo = TRUE, tidy.opts=list(width.cutoff=60),tidy=TRUE)
# Calculate precision using dynamic column names
calcPrecision <- function(df, actualCol, predictedCol) {
TP <- nrow(df %>% filter((!!sym(actualCol)) == 1 & (!!sym(predictedCol)) == 1))
FP <- nrow(df %>% filter((!!sym(actualCol)) == 0 & (!!sym(predictedCol)) == 1))
return(TP / (TP + FP))
}
calcPrecision(df, 'class', 'scored.class')
knitr::opts_chunk$set(echo = TRUE, tidy.opts=list(width.cutoff=60),tidy=TRUE)
library(pROC)
library(caret)
library(tidyverse)
# load data set
class_df <- read.csv("https://raw.githubusercontent.com/letisalba/Data_621/master/Homework_2/csv/classification-output-data.csv")
head(class_df, n = 4)
summary(class_df)
str(class_df)
class_df %>%
select(class, scored.class) %>%
# re-coding to label the 0's and 1's
mutate(class = recode(class,
'0' = 'Actual Negative',
'1' = 'Actual Positive'),
scored.class = recode(scored.class,
'0' = 'Predicted Negative',
'1' = 'Predicted Positive')) %>%
table()
func.accuracy <- function (class_df, actual, predict) {
accuracy <- sum(class_df[actual] == class_df[predict]) / nrow(class_df)
return (accuracy)
}
paste0('The accuracy of the predictions is ', round(func.accuracy(class_df,"class","scored.class"),5))
func.error_rate <- function(data) {
df <- data %>%
mutate(TP = ifelse(class == 1 & scored.class == 1,1,0),
TN = ifelse(class == 0 & scored.class == 0,1,0),
FP = ifelse(class == 0 & scored.class == 1,1,0),
FN = ifelse(class == 1 & scored.class == 0,1,0))
TP = sum(df$TP)
TN = sum(df$TN)
FP = sum(df$FP)
FN = sum(df$FN)
return((FP+FN)/(TP+FP+TN+FN))
}
error_rate <- func.error_rate(class_df)
#accuracy <- func.accuracy(class_df)
accuracy <- func.accuracy(class_df,"class","scored.class")
# Verify that you get an accuracy and an error rate that sums to one.
paste0('The accuracy and error rate sums to ', (accuracy + error_rate))
func.precision <- function(data) {
df <- data %>%
mutate(TP = ifelse(class == 1 & scored.class == 1,1,0),
FP = ifelse(class == 0 & scored.class == 1,1,0))
TP = sum(df$TP)
FP = sum(df$FP)
return(TP/(TP+FP))
}
paste0('The precision of the predictions is ',round(func.precision(class_df),5))
func.sensitivity <- function(data) {
df <- data %>%
mutate(TP = ifelse(class == 1 & scored.class == 1,1,0),
FN = ifelse(class == 1 & scored.class == 0,1,0))
TP = sum(df$TP)
FN = sum(df$FN)
return(TP/(TP+FN))
}
paste0('The sensitivity of the predictions is ', round(func.sensitivity(class_df),5))
func.specificity <- function(data) {
df <- data %>%
mutate(TN = ifelse(class == 0 & scored.class == 0,1,0),
FP = ifelse(class == 0 & scored.class == 1,1,0))
TN = sum(df$TN)
FP = sum(df$FP)
return(TN/(TN+FP))
}
paste0('The specificity of the predictions is ', round(func.specificity(class_df),5))
# Calculate precision using dynamic column names
calcPrecision <- function(df, actualCol, predictedCol) {
TP <- nrow(df %>% filter((!!sym(actualCol)) == 1 & (!!sym(predictedCol)) == 1))
FP <- nrow(df %>% filter((!!sym(actualCol)) == 0 & (!!sym(predictedCol)) == 1))
return(TP / (TP + FP))
}
calcPrecision(df, 'class', 'scored.class')
dplyr::filter
# Calculate precision using dynamic column names
calcPrecision <- function(df, actualCol, predictedCol) {
TP <- nrow(df %>% filter((!!sym(actualCol)) == 1 & (!!sym(predictedCol)) == 1))
FP <- nrow(df %>% filter((!!sym(actualCol)) == 0 & (!!sym(predictedCol)) == 1))
return(TP / (TP + FP))
}
calcPrecision(df, 'class', 'scored.class')
# Calculate precision using dynamic column names
calcPrecision <- function(df, actualCol, predictedCol) {
TP <- nrow(df %>% filter((!!sym(actualCol)) == 1 & (!!sym(predictedCol)) == 1))
FP <- nrow(df %>% filter((!!sym(actualCol)) == 0 & (!!sym(predictedCol)) == 1))
return(TP / (TP + FP))
}
calcPrecision(df, 'class', 'scored.class')
# Calculate precision using dynamic column names
calcPrecision <- function(df, actualCol, predictedCol) {
TP <- nrow(df %>% dplyr::filter((!!sym(actualCol)) == 1 & (!!sym(predictedCol)) == 1))
FP <- nrow(df %>% dplyr::filter((!!sym(actualCol)) == 0 & (!!sym(predictedCol)) == 1))
return(TP / (TP + FP))
}
calcPrecision(df, 'class', 'scored.class')
library(pROC)
library(caret)
library(tidyverse)
library(dplyr::filter)
library(pROC)
library(caret)
library(tidyverse)
library(dplyr)
knitr::opts_chunk$set(echo = TRUE, tidy.opts=list(width.cutoff=60),tidy=TRUE)
library(pROC)
library(caret)
library(tidyverse)
library(dplyr)
# load data set
class_df <- read.csv("https://raw.githubusercontent.com/letisalba/Data_621/master/Homework_2/csv/classification-output-data.csv")
head(class_df, n = 4)
summary(class_df)
str(class_df)
class_df %>%
select(class, scored.class) %>%
# re-coding to label the 0's and 1's
mutate(class = recode(class,
'0' = 'Actual Negative',
'1' = 'Actual Positive'),
scored.class = recode(scored.class,
'0' = 'Predicted Negative',
'1' = 'Predicted Positive')) %>%
table()
func.accuracy <- function (class_df, actual, predict) {
accuracy <- sum(class_df[actual] == class_df[predict]) / nrow(class_df)
return (accuracy)
}
paste0('The accuracy of the predictions is ', round(func.accuracy(class_df,"class","scored.class"),5))
func.error_rate <- function(data) {
df <- data %>%
mutate(TP = ifelse(class == 1 & scored.class == 1,1,0),
TN = ifelse(class == 0 & scored.class == 0,1,0),
FP = ifelse(class == 0 & scored.class == 1,1,0),
FN = ifelse(class == 1 & scored.class == 0,1,0))
TP = sum(df$TP)
TN = sum(df$TN)
FP = sum(df$FP)
FN = sum(df$FN)
return((FP+FN)/(TP+FP+TN+FN))
}
error_rate <- func.error_rate(class_df)
#accuracy <- func.accuracy(class_df)
accuracy <- func.accuracy(class_df,"class","scored.class")
# Verify that you get an accuracy and an error rate that sums to one.
paste0('The accuracy and error rate sums to ', (accuracy + error_rate))
func.precision <- function(data) {
df <- data %>%
mutate(TP = ifelse(class == 1 & scored.class == 1,1,0),
FP = ifelse(class == 0 & scored.class == 1,1,0))
TP = sum(df$TP)
FP = sum(df$FP)
return(TP/(TP+FP))
}
paste0('The precision of the predictions is ',round(func.precision(class_df),5))
func.sensitivity <- function(data) {
df <- data %>%
mutate(TP = ifelse(class == 1 & scored.class == 1,1,0),
FN = ifelse(class == 1 & scored.class == 0,1,0))
TP = sum(df$TP)
FN = sum(df$FN)
return(TP/(TP+FN))
}
paste0('The sensitivity of the predictions is ', round(func.sensitivity(class_df),5))
func.specificity <- function(data) {
df <- data %>%
mutate(TN = ifelse(class == 0 & scored.class == 0,1,0),
FP = ifelse(class == 0 & scored.class == 1,1,0))
TN = sum(df$TN)
FP = sum(df$FP)
return(TN/(TN+FP))
}
paste0('The specificity of the predictions is ', round(func.specificity(class_df),5))
# Calculate precision using dynamic column names
calcPrecision <- function(df, actualCol, predictedCol) {
TP <- nrow(df %>% filter((!!sym(actualCol)) == 1 & (!!sym(predictedCol)) == 1))
FP <- nrow(df %>% filter((!!sym(actualCol)) == 0 & (!!sym(predictedCol)) == 1))
return(TP / (TP + FP))
}
calcPrecision(df, 'class', 'scored.class')
# Calculate precision using dynamic column names
calcPrecision <- function(class_df, actualCol, predictedCol) {
TP <- nrow(df %>% filter((!!sym(actualCol)) == 1 & (!!sym(predictedCol)) == 1))
FP <- nrow(df %>% filter((!!sym(actualCol)) == 0 & (!!sym(predictedCol)) == 1))
return(TP / (TP + FP))
}
calcPrecision(class_df, 'class', 'scored.class')
library(pROC)
library(caret)
library(tidyverse)
library(dplyr)
library(pROC)
library(caret)
library(tidyverse)
library(dplyr)
# load data set
class_df <- read.csv("https://raw.githubusercontent.com/letisalba/Data_621/master/Homework_2/csv/classification-output-data.csv")
head(class_df, n = 4)
summary(class_df)
str(class_df)
class_df %>%
select(class, scored.class) %>%
# re-coding to label the 0's and 1's
mutate(class = recode(class,
'0' = 'Actual Negative',
'1' = 'Actual Positive'),
scored.class = recode(scored.class,
'0' = 'Predicted Negative',
'1' = 'Predicted Positive')) %>%
table()
tinytex::install_tinytex()
